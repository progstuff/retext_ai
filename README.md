# retext_ai
- API написан с использованием Flask  
- для определения корней русских слов используется библиотека morpholog  
- для определения русских синонимов используется библиотека ru_synonyms  
- для определения корней английских слов используется nltk.stem.snowball  
- для определения синонимов английских слов используется nltk.corpus  

Пример ответа на запрос  {"words": ["words", "котик"]}  
![с1](https://user-images.githubusercontent.com/49985639/228961223-6d9af824-7d67-4ff5-b7a4-7abe562b8b3d.PNG)  

Пример ответа на запрос {"words": ["house", "паром"]}  
![c4](https://user-images.githubusercontent.com/49985639/228961117-9fb3f781-c068-4eb3-9a80-ff5396d8cee9.PNG)  

Пример ответа на запрос с ошибкой - неверное название ключа words {"wods": ["house", "паром"]}  
![с2](https://user-images.githubusercontent.com/49985639/228961597-efabe242-0020-4829-b75e-3f342b6b5f2c.PNG)  

Пример ответа на запрос с ошибкой- неверный тип данных  
![c3](https://user-images.githubusercontent.com/49985639/228961791-a591de2c-f2a5-44cd-9096-d2cb6afa7dba.PNG)  

Вся логика содержится в классе WordProcessor. Внутри него 2 объекта для обработки русских и английских слов. За это отвечает соответственно RussianWordsProcessing и EnglishWordsProcessing. Для работы создаётся один экземпляр класса WordProcessor, который используется внутри класса RootsAPI.  
Метод get_roots класса WordProcessor сначала определяет язык и что слово состоит из букв, затем определяются синонимы для слова, удаляются повторы, потом определяются корни синонимов и исходного слова и опять удаляются повторы  

# Установка  
- установить библиотеки из файла requirements.txt
- отдельно установить пакеты данных для правильной работы библиотеки nltk (около 3 Гб) как указано здесь https://www.nltk.org/data.html#




